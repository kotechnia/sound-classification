
# sound-classification

â sound-classificationì˜ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤
```bash
ğŸ“‚
â”œâ”€ ğŸ“‚data ( NIA datasets )
â”œâ”€ ğŸ“‚docker
â”œâ”€ ğŸ“‚ignite_trainer
â”œâ”€ ğŸ“‚model
â”œâ”€ ğŸ“‚protocols
â”‚   â””â”€ ğŸ“‚nia2022
â”œâ”€ ğŸ“‚reproduced
â”œâ”€ ğŸ“‚utils
â”œâ”€ ğŸ“‚visdom_env
â”œâ”€ ğŸ“„README.md
â”œâ”€ ğŸ“„main.py
â”œâ”€ ğŸ“‰dataset.csv
â”œâ”€ ğŸ“„prepare.py
â”œâ”€ ğŸ“„requirements.txt
â”œâ”€ ğŸ“‰results.csv
â””â”€ ğŸ“„test.py
```

â í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì‚¬ì–‘ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.    
```
Ubuntu 22.04   
Python 3.8.10 
Torch 1.7.0+cu110
Torchvision==0.8.1+cu110
CUDA 11.1
cuDnn 8.2.0    
```
â ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.

```
$ pip install â€“r requirements.txt
```

# ì‹¤í–‰ ë°©ë²•

â dataset.csv(input csv) ìƒì„± ë°©ë²•ì…ë‹ˆë‹¤.
```
python prepare.py
```
â dataset.csv êµ¬ì¡°
|filename|fold|target|
|:--:|:--:|:--:|
|data/1.Training/sound_1.wav|train|0|
|data/2.Validation/sound_2.wav|val|1|
|:|:|:|
|data/3.Test/sound_n.wav|test|7|     

â í›ˆë ¨ ë°©ë²•ì…ë‹ˆë‹¤.
```
python main.py --config=protocols/nia2022/nia2022.json
```


â ê²€ì¦ ë°©ë²•ì…ë‹ˆë‹¤.
```
python test.py
```

# NIA 2022 sound-classification  
â NIA 2022 AI í•™ìŠµìš© ë°ì´í„°ë¡œ 8:1:1 í›ˆë ¨, ê²€ì¦, ì‹¤í—˜ ë¶„í•  í•™ìŠµ ì§„í–‰  
```
NIA 2022 sound-classification ë°ì´í„° ì´ 1053h -> train 843h valid 105h test 105h  
```
â€» ì „ì²´ ë°ì´í„°ëŠ” [AI - HUB](https://aihub.or.kr/)ì—ì„œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  


â í›ˆë ¨ëœ ëª¨ë¸ì˜ F1-Score ê²°ê³¼ì…ë‹ˆë‹¤.  
||**ESResNet**|
|:--:|:--:|
|**F1-score**|0.88|



--- 

<details>
    <summary><b>â  original github & paper</b></summary>
    <p>github : <a href='https://github.com/AndreyGuzhov/ESResNet'>ESResNet</a>
    <p>paper : <a href='https://arxiv.org/abs/2004.07301'>arXiv:2004.07301</a>
</details>    

